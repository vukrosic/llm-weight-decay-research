{
  "final_metrics": {
    "val_loss": 6.151898951530456,
    "val_accuracy": 0.1709904738641915,
    "val_perplexity": 469.6083040180009,
    "train_loss": 6.226797103881836
  },
  "setup_time_seconds": 2.01285719871521,
  "active_training_time_seconds": 77.082998752594,
  "total_wall_time_seconds": 79.0958559513092,
  "total_time_minutes": 1.3182642658551533,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": -0.01,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884678564071656,
      6.663970260620117,
      6.359193105697631,
      6.151898951530456
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.14521739130434783,
      0.15727405959941376,
      0.1709904738641915
    ],
    "val_perplexities": [
      53352.63061153642,
      783.6560878243762,
      577.7799608946274,
      469.6083040180009
    ],
    "elapsed_times": [
      0.15479485988616942,
      0.5393496036529541,
      0.9219272255897522,
      1.2847152511278788
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.896004676818848,
      7.168900966644287,
      6.699944019317627,
      6.546363353729248,
      6.510814189910889,
      6.387603282928467,
      6.3727216720581055,
      6.362936973571777
    ],
    "train_loss_elapsed_minutes": [
      0.02159010966618856,
      0.25656718015670776,
      0.3564474503199259,
      0.589889669418335,
      0.6896141211191813,
      0.7892964243888855,
      1.0222095330556233,
      1.1221211791038512
    ]
  }
}