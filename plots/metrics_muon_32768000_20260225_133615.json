{
  "final_metrics": {
    "val_loss": 4.419494299888611,
    "val_accuracy": 0.28559294088910603,
    "val_perplexity": 83.05427418100588,
    "train_loss": 4.018497943878174
  },
  "setup_time_seconds": 5.293341875076294,
  "active_training_time_seconds": 358.9398789405823,
  "total_wall_time_seconds": 364.23322081565857,
  "total_time_minutes": 6.070553680260976,
  "actual_steps": 2000,
  "tokens_seen": 32768000,
  "train_tokens": 32768000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": 0.1,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      500,
      1000,
      2000
    ],
    "val_losses": [
      10.884659748077393,
      5.230547676086426,
      4.750445628166199,
      4.419494299888611
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.2249957254518808,
      0.25627381533952126,
      0.28559294088910603
    ],
    "val_perplexities": [
      53351.62673818938,
      186.89513349105366,
      115.6358036182694,
      83.05427418100588
    ],
    "elapsed_times": [
      0.14641644954681396,
      1.6299672524134319,
      3.10932834148407,
      5.982330052057902
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      250,
      500,
      750,
      1000,
      1250,
      1500,
      1750
    ],
    "train_loss_tokens": [
      16384,
      4112384,
      8208384,
      12304384,
      16400384,
      20496384,
      24592384,
      28688384
    ],
    "train_losses": [
      10.892380714416504,
      5.894152641296387,
      5.3206000328063965,
      5.019041538238525,
      4.2066144943237305,
      4.7432050704956055,
      4.502280235290527,
      4.523627281188965
    ],
    "train_loss_elapsed_minutes": [
      0.039095830917358396,
      0.8504800756772359,
      1.5510059078534444,
      2.3305113037427265,
      3.030377280712128,
      3.8084887623786927,
      4.507428467273712,
      5.207103192806244
    ]
  }
}