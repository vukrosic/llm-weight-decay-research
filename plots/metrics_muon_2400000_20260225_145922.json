{
  "final_metrics": {
    "val_loss": 6.148560338020324,
    "val_accuracy": 0.17171836834391793,
    "val_perplexity": 468.0430776865032,
    "train_loss": 6.220367431640625
  },
  "setup_time_seconds": 1.2001888751983643,
  "active_training_time_seconds": 77.1642713546753,
  "total_wall_time_seconds": 78.36446022987366,
  "total_time_minutes": 1.306074337164561,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": -0.01,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884679203033448,
      6.658959236145019,
      6.356793060302734,
      6.148560338020324
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.14553431851489984,
      0.15777479237909137,
      0.17171836834391793
    ],
    "val_perplexities": [
      53352.66470183977,
      779.7389905201024,
      576.3949254989719,
      468.0430776865032
    ],
    "elapsed_times": [
      0.15548428297042846,
      0.539335310459137,
      0.9229364156723022,
      1.286069655418396
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.895920753479004,
      7.166533946990967,
      6.6984076499938965,
      6.543642520904541,
      6.509526252746582,
      6.384952545166016,
      6.372554302215576,
      6.361807823181152
    ],
    "train_loss_elapsed_minutes": [
      0.02236252228418986,
      0.2568752924601237,
      0.35691262483596803,
      0.5898237744967143,
      0.6898513476053874,
      0.7903297543525696,
      1.023005445798238,
      1.1233112533887228
    ]
  }
}