{
  "final_metrics": {
    "val_loss": 6.150596756935119,
    "val_accuracy": 0.17094894968246213,
    "val_perplexity": 468.99718060974027,
    "train_loss": 6.2241129875183105
  },
  "setup_time_seconds": 1.222022533416748,
  "active_training_time_seconds": 77.15111684799194,
  "total_wall_time_seconds": 78.37313938140869,
  "total_time_minutes": 1.3062189896901448,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": 0.01,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884678564071656,
      6.662911891937256,
      6.358174118995667,
      6.150596756935119
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.14498839765510504,
      0.15752870053737175,
      0.17094894968246213
    ],
    "val_perplexities": [
      53352.63061153642,
      782.8271295120271,
      577.1915106602132,
      468.99718060974027
    ],
    "elapsed_times": [
      0.1550618847211202,
      0.5393290082613628,
      0.9224777897198995,
      1.2858504931131998
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.896004676818848,
      7.167263984680176,
      6.699742794036865,
      6.548192501068115,
      6.511238098144531,
      6.377755641937256,
      6.3734354972839355,
      6.361016750335693
    ],
    "train_loss_elapsed_minutes": [
      0.02174290418624878,
      0.256803826491038,
      0.3567107041676839,
      0.5898733258247375,
      0.68952476978302,
      0.7896968841552734,
      1.0229308485984803,
      1.1228296041488648
    ]
  }
}