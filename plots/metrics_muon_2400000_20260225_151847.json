{
  "final_metrics": {
    "val_loss": 6.148558826446533,
    "val_accuracy": 0.17170310210063508,
    "val_perplexity": 468.04237020538835,
    "train_loss": 6.224445343017578
  },
  "setup_time_seconds": 1.1896123886108398,
  "active_training_time_seconds": 77.21474599838257,
  "total_wall_time_seconds": 78.40435838699341,
  "total_time_minutes": 1.3067393064498902,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": 0.01,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884679203033448,
      6.663531341552734,
      6.356318421363831,
      6.148558826446533
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.14490779189057157,
      0.15758671226184662,
      0.17170310210063508
    ],
    "val_perplexities": [
      53352.66470183977,
      783.3122016997687,
      576.1214109386091,
      468.04237020538835
    ],
    "elapsed_times": [
      0.1554625113805135,
      0.5398577173550924,
      0.9235692421595255,
      1.2869110186894734
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.895920753479004,
      7.166720867156982,
      6.6997151374816895,
      6.546953201293945,
      6.509092807769775,
      6.378934860229492,
      6.371248722076416,
      6.3641180992126465
    ],
    "train_loss_elapsed_minutes": [
      0.022223496437072755,
      0.2571384787559509,
      0.35744594732920326,
      0.5905502716700236,
      0.6906701326370239,
      0.790950866540273,
      1.0239850560824075,
      1.1238822062810263
    ]
  }
}