{
  "final_metrics": {
    "val_loss": 6.154702796936035,
    "val_accuracy": 0.17015327308255984,
    "val_perplexity": 470.9268607544423,
    "train_loss": 6.225924015045166
  },
  "setup_time_seconds": 1.1567416191101074,
  "active_training_time_seconds": 77.31875276565552,
  "total_wall_time_seconds": 78.47549438476562,
  "total_time_minutes": 1.3079249064127605,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": 0.0,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884679203033448,
      6.666398243904114,
      6.357387251853943,
      6.154702796936035
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.14449438202247192,
      0.1571146800195408,
      0.17015327308255984
    ],
    "val_perplexities": [
      53352.66470183977,
      785.5611034431998,
      576.7375162660531,
      470.9268607544423
    ],
    "elapsed_times": [
      0.15625720421473185,
      0.5411762754122417,
      0.9252004583676656,
      1.2886444687843324
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.895920753479004,
      7.169299602508545,
      6.706532001495361,
      6.549158096313477,
      6.5107293128967285,
      6.381363391876221,
      6.375485897064209,
      6.364892482757568
    ],
    "train_loss_elapsed_minutes": [
      0.022905242443084717,
      0.2585717558860779,
      0.3584936817487081,
      0.5923206210136414,
      0.6923694054285685,
      0.7924914360046387,
      1.025840441385905,
      1.1260430057843527
    ]
  }
}