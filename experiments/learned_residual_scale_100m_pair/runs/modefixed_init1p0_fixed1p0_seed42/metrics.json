{
  "final_metrics": {
    "val_loss": 3.7473718333244324,
    "val_accuracy": 0.3485747435271129,
    "val_perplexity": 42.40947623286105,
    "train_loss": 3.7727367877960205
  },
  "setup_time_seconds": 6.178148508071899,
  "active_training_time_seconds": 1069.5976724624634,
  "total_wall_time_seconds": 1075.7758209705353,
  "total_time_minutes": 17.929597016175588,
  "actual_steps": 6104,
  "tokens_seen": 100007936,
  "train_tokens": 100000000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": 0.0,
    "muon_decay_mode": "param",
    "residual_scale": 1.0,
    "residual_scale_mode": "fixed",
    "residual_scale_init": 1.0,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "learned_scale_summary": {},
  "history": {
    "steps": [
      0,
      500,
      1000,
      2000,
      3000,
      4000,
      5000,
      6104
    ],
    "val_losses": [
      10.884659748077393,
      5.215655279159546,
      4.718573355674744,
      4.221424491405487,
      4.013838987350464,
      3.8945270204544067,
      3.8153505873680116,
      3.7473718333244324
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.22660173424523694,
      0.25844162188568637,
      0.30592696629213484,
      0.32491145578895947,
      0.33531753786028334,
      0.3424236687835857,
      0.3485747435271129
    ],
    "val_perplexities": [
      53351.62673818938,
      184.13243960616472,
      112.00834256121213,
      68.13046646181131,
      55.35898559492652,
      49.13280905237624,
      45.39266768952503,
      42.40947623286105
    ],
    "elapsed_times": [
      0.14659581979115804,
      1.6262361447016398,
      3.105496935049693,
      5.980369647343953,
      8.865802264213562,
      11.746668553352356,
      14.634457858403524,
      17.82662649154663
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024,
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      250,
      500,
      750,
      1000,
      1250,
      1500,
      1750,
      2000,
      2250,
      2500,
      2750,
      3000,
      3250,
      3500,
      3750,
      4000,
      4250,
      4500,
      4750,
      5000,
      5250,
      5500,
      5750,
      6000
    ],
    "train_loss_tokens": [
      16384,
      4112384,
      8208384,
      12304384,
      16400384,
      20496384,
      24592384,
      28688384,
      32784384,
      36880384,
      40976384,
      45072384,
      49168384,
      53264384,
      57360384,
      61456384,
      65552384,
      69648384,
      73744384,
      77840384,
      81936384,
      86032384,
      90128384,
      94224384,
      98320384
    ],
    "train_losses": [
      10.892380714416504,
      5.904298782348633,
      5.31019401550293,
      5.004432201385498,
      4.175514221191406,
      4.669528961181641,
      4.373287200927734,
      4.388776779174805,
      4.384521961212158,
      4.24460506439209,
      4.181469917297363,
      4.046412467956543,
      3.8997769355773926,
      3.882709264755249,
      4.167819023132324,
      3.839223623275757,
      3.833617925643921,
      3.9078476428985596,
      3.8569118976593018,
      3.768226385116577,
      3.8917698860168457,
      3.9939823150634766,
      3.905233383178711,
      3.8588509559631348,
      3.918846368789673
    ],
    "train_loss_elapsed_minutes": [
      0.03915096521377563,
      0.8472111940383911,
      1.5471012075742085,
      2.3266061743100486,
      3.0264636953671773,
      3.8043465415636697,
      4.503546599547068,
      5.202643672625224,
      5.901385434468588,
      6.680934866269429,
      7.385787689685822,
      8.085916431744893,
      8.786839083830516,
      9.566354938348134,
      10.266804993152618,
      10.967863762378693,
      11.667602316538494,
      12.44843107064565,
      13.148916749159495,
      13.849520222345989,
      14.55527716477712,
      15.346780784924825,
      16.052424546082815,
      16.758523233731587,
      17.458996148904166
    ]
  }
}