{
  "final_metrics": {
    "val_loss": 6.154239573478699,
    "val_accuracy": 0.17010747435271129,
    "val_perplexity": 470.70876690284496,
    "train_loss": 6.228179454803467
  },
  "setup_time_seconds": 2.4063658714294434,
  "active_training_time_seconds": 77.2796573638916,
  "total_wall_time_seconds": 79.68602323532104,
  "total_time_minutes": 1.3281003872553507,
  "actual_steps": 147,
  "tokens_seen": 2408448,
  "train_tokens": 2400000,
  "experiment_config": {
    "optimizer_type": "muon",
    "muon_lr": 0.024,
    "muon_weight_decay": -0.01,
    "adamw_lr": 0.0005,
    "batch_size": 8,
    "gradient_accumulation_steps": 1
  },
  "history": {
    "steps": [
      0,
      50,
      100,
      147
    ],
    "val_losses": [
      10.884679203033448,
      6.666048369407654,
      6.358236036300659,
      6.154239573478699
    ],
    "val_accuracies": [
      0.00823400097703957,
      0.1445969711773327,
      0.15715009770395702,
      0.17010747435271129
    ],
    "val_perplexities": [
      53352.66470183977,
      785.2863037232041,
      577.2272499094454,
      470.70876690284496
    ],
    "elapsed_times": [
      0.15501636266708374,
      0.5401071190834046,
      0.9241401791572571,
      1.2879928588867187
    ],
    "learning_rates": [
      0.024,
      0.024,
      0.024,
      0.024
    ],
    "train_loss_steps": [
      0,
      20,
      40,
      60,
      80,
      100,
      120,
      140
    ],
    "train_loss_tokens": [
      16384,
      344064,
      671744,
      999424,
      1327104,
      1654784,
      1982464,
      2310144
    ],
    "train_losses": [
      10.895920753479004,
      7.168910503387451,
      6.705722332000732,
      6.548818111419678,
      6.510936260223389,
      6.3835835456848145,
      6.3765130043029785,
      6.365156650543213
    ],
    "train_loss_elapsed_minutes": [
      0.02172854741414388,
      0.2569617986679077,
      0.3572287201881409,
      0.590860915184021,
      0.6910385608673095,
      0.7916028658548991,
      1.0248093962669373,
      1.124967352549235
    ]
  }
}